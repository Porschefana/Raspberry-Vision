#include <cscore.h>
#include <ntcore.h>
#include <networktables/NetworkTableInstance.h>
#include <opencv2/core/core.hpp>
#include <opencv2/videoio/videoio.hpp>
#include <opencv2/imgproc/imgproc.hpp>
#include <iostream>
#include <stdio.h>  /* printf() */
#include <string.h> /* memcpy() */
#include <inttypes.h>

#include <chrono>
#include <thread>

#include <VisionPipeline.h>
#include "pipeline/GripPipeline.h" /* This file is auto-generated by Grip */

using namespace cs;
using namespace nt;
using namespace cv;
using namespace frc;
using namespace grip;

#ifndef NULL
#define NULL 0
#endif

int main() {
	/* Instantiate pipeline exported from GRIP.  If not using grip, set pipeline = NULL; */
	GripPipeline *p_pipeline = new GripPipeline();
	
	const char* p_outputVideoFilePath = "output.avi"; /* Set to NULL if video writing not desired */

	/* Connect NetworkTables */
	/* Note:  actual IP address should be robot IP address */
	NetworkTableInstance inst = NetworkTableInstance::GetDefault();
	inst.StartClient("192.168.0.113");

	/* Open connection to USB Camera (video device 0 [/dev/video0]) */
	UsbCamera camera("usbcam", 0);

	/* Configure Camera */
	/* Note:  Higher resolution & framerate is possible, depending upon processing cpu usage */
	double width = 320;
	double height = 240;
	int frames_per_sec = 15;
	camera.SetVideoMode(VideoMode::PixelFormat::kMJPEG, width, height, frames_per_sec);
		
	/* Start raw Video Streaming Server */
	MjpegServer rawVideoServer("raw_video_server", 8081);
	rawVideoServer.SetSource(camera);
	CvSink cvsink("cvsink");
	cvsink.SetSource(camera);

	/* Start processed Video server */
	CvSource cvsource("cvsource",
	VideoMode::PixelFormat::kMJPEG, width, height, frames_per_sec);
	MjpegServer processedVideoServer("processed_video_server", 8082);
	processedVideoServer.SetSource(cvsource);

	/* Create Video Writer, if enabled */
	Size frameSize(width, height);
	VideoWriter *p_videoWriter = NULL;
	if (p_outputVideoFilePath != NULL)
	{
		p_videoWriter = new VideoWriter(p_outputVideoFilePath,
		VideoWriter::fourcc('F', 'M', 'P', '4'), (double)frames_per_sec, frameSize, true);
	}

	/* Pre-allocate a video frame */
	Mat frame;

	int count = 0;
	while (count < 500) {
		/* Acquire new video frame */
		std::string videoTimestampString;
		uint64_t video_timestamp = cvsink.GrabFrame(frame);
		if (video_timestamp == 0)
		{
			std::string error_string = cvsink.GetError();
			printf("Error Grabbing Video Frame:  %s\n", error_string.c_str());
			std::this_thread::sleep_for(std::chrono::milliseconds((1000/frames_per_sec)/2));
			continue;
		}
		else
		{
			videoTimestampString = std::to_string(video_timestamp);
			//printf("Video Timestamp:  %llu\n", video_timestamp);
		}

		/* Update Network Tables with timestamps & orientation data */
		inst.GetEntry("/vmx/videoOSTimestamp").SetDouble(video_timestamp);

		/* Invoke processing pipeline, if one is present */
		if (p_pipeline != NULL) {
			p_pipeline->Process(frame);
		}
		std::vector<std::vector<cv::Point> > inputContours = *p_pipeline->GetFilterContoursOutput();
		for (std::vector<cv::Point> contour: inputContours)
		{
			int rectangle_height = boundingRect(contour).height;
			int rectangle_width = boundingRect(contour).width;
			std::cout << "Largeur: " << rectangle_width << "		" << "Hauteur: " << rectangle_height << std::endl;
			
			cv::Point Top_left_corner = boundingRect(contour).tl();
			double centre_x = ((Top_left_corner.x + (rectangle_width/2)) - (width/2)) / (width/2);
			double centre_y = ((Top_left_corner.y + (rectangle_height/2)) - (height/2)) / (height/2);
			std::cout << "X = " << centre_x << "		" << "Y = " << centre_y << std::endl;
		}

		/* Write Frame to video */
		if (p_videoWriter != NULL) {
			p_videoWriter->write(frame);
		}

		count++;
	}
	if (p_videoWriter != NULL) {
		delete p_videoWriter;
	}
	if (p_pipeline != NULL) {
		delete p_pipeline;
	}
}

